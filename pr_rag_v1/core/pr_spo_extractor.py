#!/usr/bin/env python3
"""
SPOä¸‰å…ƒç»„æå–å™¨
åŸºäºLLMçš„Subject-Predicate-Objectä¸‰å…ƒç»„æå–
æ•´åˆè‡ªFareed Khançš„çŸ¥è¯†å›¾è°±æ„å»ºæ–¹æ³•
"""

import os
import json
import re
from typing import List, Dict, Any, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

try:
    import openai
except ImportError:
    print("âš ï¸ è­¦å‘Š: openaiåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openai")
    openai = None


class SPOTripleExtractor:
    """SPOä¸‰å…ƒç»„æå–å™¨"""
    
    def __init__(
        self,
        model_name: str = "deepseek/deepseek-chat-v3-0324",
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        temperature: float = 0.0,
        max_tokens: int = 4096,
        use_openrouter: bool = True
    ):
        """
        åˆå§‹åŒ–SPOä¸‰å…ƒç»„æå–å™¨
        
        Args:
            model_name: LLMæ¨¡å‹åç§°
            api_key: APIå¯†é’¥ï¼ˆå¦‚æœä¸ºNoneï¼Œå°†ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            base_url: APIåŸºç¡€URLï¼ˆå¦‚æœä¸ºNoneï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ï¼‰
            temperature: ç”Ÿæˆæ¸©åº¦ï¼ˆ0.0ç”¨äºç¡®å®šæ€§æå–ï¼‰
            max_tokens: æœ€å¤§tokenæ•°
            use_openrouter: æ˜¯å¦ä½¿ç”¨OpenRouterï¼ˆå¦åˆ™ä½¿ç”¨OpenAIï¼‰
        """
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        # é…ç½®API
        if use_openrouter:
            self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
            self.base_url = base_url or "https://openrouter.ai/api/v1"
        else:
            self.api_key = api_key or os.getenv("OPENAI_API_KEY")
            self.base_url = base_url or None
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        if not self.api_key:
            raise ValueError(
                "API keyæœªè®¾ç½®ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENROUTER_API_KEY æˆ– OPENAI_API_KEYï¼Œ"
                "æˆ–è€…åœ¨åˆå§‹åŒ–æ—¶ä¼ å…¥api_keyå‚æ•°ã€‚"
            )
        
        try:
            self.client = openai.OpenAI(
                base_url=self.base_url,
                api_key=self.api_key
            )
        except Exception as e:
            raise Exception(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # ç³»ç»Ÿæç¤ºè¯
        self.extraction_system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“é—¨çš„çŸ¥è¯†å›¾è°±æå–ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šæ–‡æœ¬ä¸­è¯†åˆ«å¹¶æå–äº‹å®æ€§çš„Subject-Predicate-Object (SPO) ä¸‰å…ƒç»„ã€‚
ä¸“æ³¨äºå‡†ç¡®æ€§ï¼Œå¹¶ä¸¥æ ¼éµå¾ªç”¨æˆ·æç¤ºä¸­è¦æ±‚çš„JSONè¾“å‡ºæ ¼å¼ã€‚
æå–æ ¸å¿ƒå®ä½“å’Œæœ€ç›´æ¥çš„å…³ç³»ã€‚
"""
        
        # ç”¨æˆ·æç¤ºè¯æ¨¡æ¿
        self.extraction_user_prompt_template = """
è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–Subject-Predicate-Object (S-P-O) ä¸‰å…ƒç»„ã€‚

**éå¸¸é‡è¦çš„è§„åˆ™ï¼š**
1. **è¾“å‡ºæ ¼å¼ï¼š** ä»…å“åº”ä¸€ä¸ªæœ‰æ•ˆçš„JSONæ•°ç»„ã€‚æ¯ä¸ªå…ƒç´ å¿…é¡»æ˜¯ä¸€ä¸ªåŒ…å«"subject"ã€"predicate"ã€"object"é”®çš„å¯¹è±¡ã€‚
2. **ä»…JSONï¼š** ä¸è¦åœ¨JSONæ•°ç»„å‰ååŒ…å«ä»»ä½•æ–‡æœ¬ï¼ˆä¾‹å¦‚ï¼Œä¸è¦å†™"è¿™æ˜¯JSONï¼š"æˆ–è§£é‡Šï¼‰ã€‚ä¸è¦ä½¿ç”¨markdown ```json ... ```æ ‡ç­¾ã€‚
3. **ç®€æ´è°“è¯ï¼š** ä¿æŒ'predicate'å€¼ç®€æ´ï¼ˆ1-3ä¸ªè¯ï¼Œç†æƒ³æƒ…å†µä¸‹1-2ä¸ªè¯ï¼‰ã€‚ä½¿ç”¨åŠ¨è¯æˆ–çŸ­åŠ¨è¯çŸ­è¯­ï¼ˆä¾‹å¦‚ï¼Œ'discovered'ã€'was born in'ã€'won'ï¼‰ã€‚
4. **å°å†™ï¼š** 'subject'ã€'predicate'å’Œ'object'çš„æ‰€æœ‰å€¼å¿…é¡»ä¸ºå°å†™ã€‚
5. **ä»£è¯è§£æï¼š** å°†ä»£è¯ï¼ˆsheã€heã€itã€herç­‰ï¼‰æ›¿æ¢ä¸ºå®ƒä»¬åŸºäºæ–‡æœ¬ä¸Šä¸‹æ–‡æ‰€æŒ‡çš„ç‰¹å®šå°å†™å®ä½“åç§°ï¼ˆä¾‹å¦‚ï¼Œ'marie curie'ï¼‰ã€‚
6. **å…·ä½“æ€§ï¼š** æ•è·å…·ä½“ç»†èŠ‚ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœæŒ‡å®šäº†ï¼Œä½¿ç”¨'nobel prize in physics'è€Œä¸æ˜¯ä»…ä»…'nobel prize'ï¼‰ã€‚
7. **å®Œæ•´æ€§ï¼š** æå–æ‰€æœ‰æåˆ°çš„ä¸åŒäº‹å®å…³ç³»ã€‚

**è¦å¤„ç†çš„æ–‡æœ¬ï¼š**
```text
{text_chunk}
```

**å¿…éœ€çš„JSONè¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š**
[
{{ "subject": "marie curie", "predicate": "discovered", "object": "radium" }},
{{ "subject": "marie curie", "predicate": "won", "object": "nobel prize in physics" }}
]

**ä½ çš„JSONè¾“å‡ºï¼ˆå¿…é¡»ä»¥'['å¼€å¤´ï¼Œä»¥']'ç»“å°¾ï¼‰ï¼š**
"""
    
    def chunk_text(
        self,
        text: str,
        chunk_size: int = 150,
        overlap: int = 30
    ) -> List[Dict[str, Any]]:
        """
        å°†æ–‡æœ¬åˆ†å—
        
        Args:
            text: è¦åˆ†å—çš„æ–‡æœ¬
            chunk_size: æ¯å—çš„è¯æ•°
            overlap: é‡å è¯æ•°ï¼ˆå¿…é¡»å°äºchunk_sizeï¼‰
            
        Returns:
            åˆ†å—åˆ—è¡¨ï¼Œæ¯ä¸ªå—åŒ…å«textå’Œchunk_number
        """
        if overlap >= chunk_size and chunk_size > 0:
            raise ValueError(f"é‡å ({overlap})å¿…é¡»å°äºå—å¤§å°({chunk_size})")
        
        words = text.split()
        total_words = len(words)
        chunks = []
        start_index = 0
        chunk_number = 1
        
        while start_index < total_words:
            end_index = min(start_index + chunk_size, total_words)
            chunk_text = " ".join(words[start_index:end_index])
            chunks.append({
                "text": chunk_text,
                "chunk_number": chunk_number
            })
            
            # è®¡ç®—ä¸‹ä¸€ä¸ªå—çš„èµ·å§‹ä½ç½®
            next_start_index = start_index + chunk_size - overlap
            
            # ç¡®ä¿æœ‰è¿›å±•
            if next_start_index <= start_index:
                if end_index == total_words:
                    break
                next_start_index = start_index + 1
            
            start_index = next_start_index
            chunk_number += 1
            
            # å®‰å…¨ä¸­æ–­
            if chunk_number > total_words:
                print("âš ï¸ è­¦å‘Š: åˆ†å—å¾ªç¯è¶…è¿‡æ€»è¯æ•°ï¼Œä¸­æ–­ã€‚")
                break
        
        return chunks
    
    def extract_triples_from_chunk(
        self,
        chunk_text: str,
        chunk_number: int = 1,
        verbose: bool = False
    ) -> Tuple[List[Dict[str, Any]], Optional[str]]:
        """
        ä»å•ä¸ªchunkä¸­æå–ä¸‰å…ƒç»„
        
        Args:
            chunk_text: chunkæ–‡æœ¬
            chunk_number: chunkç¼–å·
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            
        Returns:
            (triples_list, error_message) å…ƒç»„
        """
        # æ ¼å¼åŒ–ç”¨æˆ·æç¤º
        user_prompt = self.extraction_user_prompt_template.format(text_chunk=chunk_text)
        
        llm_output = None
        error_message = None
        
        try:
            if verbose:
                print(f"ğŸ“¤ å‘é€è¯·æ±‚åˆ°LLM (chunk {chunk_number})...")
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {"role": "system", "content": self.extraction_system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            # APIè°ƒç”¨å‚æ•°
            call_params = {
                "model": self.model_name,
                "messages": messages,
                "max_tokens": self.max_tokens,
            }
            
            # æŸäº›æ¨¡å‹ä¸æ”¯æŒtemperature=0.0ï¼Œä½¿ç”¨æ¡ä»¶è®¾ç½®
            try:
                call_params["temperature"] = self.temperature
            except:
                pass  # å¦‚æœæ¨¡å‹ä¸æ”¯æŒï¼Œè·³è¿‡
            
            # æŸäº›æ¨¡å‹å¯èƒ½æ”¯æŒresponse_format
            try:
                call_params["response_format"] = {"type": "json_object"}
            except:
                pass
            
            response = self.client.chat.completions.create(**call_params)
            
            if verbose:
                print(f"âœ… LLMå“åº”å·²æ¥æ”¶ (chunk {chunk_number})")
            
            # æå–åŸå§‹å“åº”å†…å®¹
            llm_output = response.choices[0].message.content.strip()
            
            if verbose:
                print(f"--- åŸå§‹LLMè¾“å‡º (Chunk {chunk_number}) ---")
                print(llm_output[:500] + "..." if len(llm_output) > 500 else llm_output)
        
        except Exception as e:
            error_message = f"APIè°ƒç”¨é”™è¯¯: {str(e)}"
            if verbose:
                print(f"âŒ {error_message}")
            return [], error_message
        
        # è§£æJSON
        parsed_json = None
        parsing_error = None
        
        if llm_output is not None:
            try:
                # ç­–ç•¥1: ç›´æ¥è§£æï¼ˆç†æƒ³æƒ…å†µï¼‰
                parsed_data = json.loads(llm_output)
                
                # å¤„ç†response_format={'type':'json_object'}è¿”å›åŒ…å«åˆ—è¡¨çš„å­—å…¸çš„æƒ…å†µ
                if isinstance(parsed_data, dict):
                    if verbose:
                        print("   ğŸ” æ£€æµ‹åˆ°å­—å…¸å“åº”ï¼Œå°è¯•æå–åˆ—è¡¨...")
                    list_values = [v for v in parsed_data.values() if isinstance(v, list)]
                    if len(list_values) == 1:
                        parsed_json = list_values[0]
                        if verbose:
                            print("      âœ… æˆåŠŸä»å­—å…¸ä¸­æå–åˆ—è¡¨")
                    elif isinstance(parsed_data, dict) and any(k in parsed_data for k in ['triples', 'results', 'data', 'items']):
                        # å°è¯•å¸¸è§çš„å…³é”®å­—
                        for key in ['triples', 'results', 'data', 'items']:
                            if key in parsed_data and isinstance(parsed_data[key], list):
                                parsed_json = parsed_data[key]
                                if verbose:
                                    print(f"      âœ… ä»å­—å…¸çš„'{key}'é”®ä¸­æå–åˆ—è¡¨")
                                break
                        else:
                            # æ£€æŸ¥æ˜¯å¦æ˜¯å•ä¸ªä¸‰å…ƒç»„å­—å…¸ï¼ˆåŒ…å«subject, predicate, objectï¼‰
                            if all(k in parsed_data for k in ['subject', 'predicate', 'object']):
                                # å•ä¸ªä¸‰å…ƒç»„ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                                parsed_json = [parsed_data]
                                if verbose:
                                    print("      âœ… æ£€æµ‹åˆ°å•ä¸ªä¸‰å…ƒç»„å­—å…¸ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨")
                            else:
                                raise ValueError("JSONå¯¹è±¡æ¥æ”¶åˆ°äº†ï¼Œä½†ä¸åŒ…å«å•ä¸ªä¸‰å…ƒç»„åˆ—è¡¨ã€‚")
                    elif all(k in parsed_data for k in ['subject', 'predicate', 'object']):
                        # å•ä¸ªä¸‰å…ƒç»„ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                        parsed_json = [parsed_data]
                        if verbose:
                            print("      âœ… æ£€æµ‹åˆ°å•ä¸ªä¸‰å…ƒç»„å­—å…¸ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨")
                    else:
                        raise ValueError("JSONå¯¹è±¡æ¥æ”¶åˆ°äº†ï¼Œä½†ä¸åŒ…å«å•ä¸ªä¸‰å…ƒç»„åˆ—è¡¨ã€‚")
                elif isinstance(parsed_data, list):
                    parsed_json = parsed_data
                    if verbose:
                        print("   âœ… æˆåŠŸç›´æ¥è§£æJSONåˆ—è¡¨")
                else:
                    raise ValueError("è§£æçš„JSONä¸æ˜¯åˆ—è¡¨æˆ–é¢„æœŸçš„å­—å…¸åŒ…è£…å™¨ã€‚")
            
            except json.JSONDecodeError as json_err:
                parsing_error = f"JSONDecodeError: {json_err}ã€‚å°è¯•æ­£åˆ™è¡¨è¾¾å¼å›é€€..."
                if verbose:
                    print(f"   âš ï¸ {parsing_error}")
                
                # ç­–ç•¥2: æ­£åˆ™è¡¨è¾¾å¼å›é€€ï¼ˆç”¨äºå¯èƒ½åŒ…è£…åœ¨æ–‡æœ¬/markdownä¸­çš„æ•°ç»„ï¼‰
                match = re.search(r'^\s*(\[.*?\])\s*$', llm_output, re.DOTALL)
                if match:
                    json_string_extracted = match.group(1)
                    if verbose:
                        print("      ğŸ” æ­£åˆ™è¡¨è¾¾å¼æ‰¾åˆ°æ½œåœ¨çš„JSONæ•°ç»„ç»“æ„")
                    try:
                        parsed_json = json.loads(json_string_extracted)
                        if verbose:
                            print("      âœ… ä»æ­£åˆ™è¡¨è¾¾å¼æå–æˆåŠŸè§£æJSON")
                        parsing_error = None
                    except json.JSONDecodeError as nested_err:
                        parsing_error = f"æ­£åˆ™è¡¨è¾¾å¼åJSONDecodeError: {nested_err}"
                        if verbose:
                            print(f"      âŒ é”™è¯¯: æ­£åˆ™è¡¨è¾¾å¼å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSON: {nested_err}")
                else:
                    parsing_error = "JSONDecodeErrorå’Œæ­£åˆ™è¡¨è¾¾å¼å›é€€éƒ½å¤±è´¥äº†ã€‚"
                    if verbose:
                        print("      âŒ é”™è¯¯: æ­£åˆ™è¡¨è¾¾å¼æ— æ³•æ‰¾åˆ°JSONæ•°ç»„ç»“æ„")
            
            except ValueError as val_err:
                parsing_error = f"ValueError: {val_err}"
                if verbose:
                    print(f"   âŒ é”™è¯¯: {parsing_error}")
        
        # éªŒè¯å¹¶æå–ä¸‰å…ƒç»„
        valid_triples = []
        
        if parsed_json is not None:
            if isinstance(parsed_json, list):
                for item in parsed_json:
                    if isinstance(item, dict) and all(k in item for k in ['subject', 'predicate', 'object']):
                        # åŸºæœ¬æ£€æŸ¥ï¼šç¡®ä¿å€¼æ˜¯å­—ç¬¦ä¸²
                        if all(isinstance(item[k], str) for k in ['subject', 'predicate', 'object']):
                            item['chunk'] = chunk_number
                            valid_triples.append(item)
                        else:
                            if verbose:
                                print(f"   âš ï¸ è·³è¿‡éå­—ç¬¦ä¸²å€¼çš„ä¸‰å…ƒç»„: {item}")
                    else:
                        if verbose:
                            print(f"   âš ï¸ è·³è¿‡ç»“æ„ä¸æ­£ç¡®çš„é¡¹: {item}")
            else:
                parsing_error = "è§£æçš„æ•°æ®ä¸æ˜¯åˆ—è¡¨ï¼Œæ— æ³•æå–ä¸‰å…ƒç»„ã€‚"
        
        if parsing_error and not valid_triples:
            return [], parsing_error
        
        return valid_triples, None
    
    def extract_triples_from_text(
        self,
        text: str,
        chunk_size: int = 150,
        overlap: int = 30,
        verbose: bool = False
    ) -> Dict[str, Any]:
        """
        ä»å®Œæ•´æ–‡æœ¬ä¸­æå–æ‰€æœ‰ä¸‰å…ƒç»„
        
        Args:
            text: è¦å¤„ç†çš„æ–‡æœ¬
            chunk_size: æ¯å—çš„è¯æ•°
            overlap: é‡å è¯æ•°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            
        Returns:
            åŒ…å«triplesã€failed_chunksç­‰ä¿¡æ¯çš„å­—å…¸
        """
        # åˆ†å—
        if verbose:
            print(f"ğŸ“ å¼€å§‹æ–‡æœ¬åˆ†å— (chunk_size={chunk_size}, overlap={overlap})...")
        chunks = self.chunk_text(text, chunk_size, overlap)
        if verbose:
            print(f"âœ… æ–‡æœ¬å·²åˆ†å‰²ä¸º {len(chunks)} ä¸ªå—")
        
        # æå–ä¸‰å…ƒç»„
        all_extracted_triples = []
        failed_chunks = []
        
        if verbose:
            print(f"\nğŸ” å¼€å§‹ä» {len(chunks)} ä¸ªå—ä¸­æå–ä¸‰å…ƒç»„...")
        
        for chunk_info in chunks:
            chunk_text = chunk_info['text']
            chunk_num = chunk_info['chunk_number']
            
            triples, error = self.extract_triples_from_chunk(
                chunk_text, chunk_num, verbose=verbose
            )
            
            if error:
                failed_chunks.append({
                    'chunk_number': chunk_num,
                    'error': error
                })
            else:
                all_extracted_triples.extend(triples)
                if verbose:
                    print(f"   âœ… Chunk {chunk_num}: æå–äº† {len(triples)} ä¸ªä¸‰å…ƒç»„")
        
        return {
            'triples': all_extracted_triples,
            'failed_chunks': failed_chunks,
            'total_chunks': len(chunks),
            'successful_chunks': len(chunks) - len(failed_chunks)
        }
    
    def normalize_triples(
        self,
        triples: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        è§„èŒƒåŒ–ä¸‰å…ƒç»„ï¼ˆå»é‡ã€æ ‡å‡†åŒ–ï¼‰
        
        Args:
            triples: åŸå§‹ä¸‰å…ƒç»„åˆ—è¡¨
            
        Returns:
            è§„èŒƒåŒ–åçš„ä¸‰å…ƒç»„åˆ—è¡¨
        """
        normalized_triples = []
        seen_triples = set()  # è·Ÿè¸ª(subject, predicate, object)å…ƒç»„
        
        for triple in triples:
            subject_raw = triple.get('subject')
            predicate_raw = triple.get('predicate')
            object_raw = triple.get('object')
            chunk_num = triple.get('chunk', 'unknown')
            
            if isinstance(subject_raw, str) and isinstance(predicate_raw, str) and isinstance(object_raw, str):
                # è§„èŒƒåŒ–
                normalized_sub = subject_raw.strip().lower()
                normalized_pred = re.sub(r'\s+', ' ', predicate_raw.strip().lower()).strip()
                normalized_obj = object_raw.strip().lower()
                
                # è¿‡æ»¤ç©ºå€¼
                if normalized_sub and normalized_pred and normalized_obj:
                    triple_identifier = (normalized_sub, normalized_pred, normalized_obj)
                    
                    # å»é‡
                    if triple_identifier not in seen_triples:
                        normalized_triples.append({
                            'subject': normalized_sub,
                            'predicate': normalized_pred,
                            'object': normalized_obj,
                            'source_chunk': chunk_num
                        })
                        seen_triples.add(triple_identifier)
        
        return normalized_triples


def test_spo_extractor():
    """æµ‹è¯•SPOæå–å™¨"""
    test_text = """
    ç›ä¸½Â·å±…é‡Œï¼ŒåŸåç›ä¸½äºšÂ·æ–¯å…‹æ²ƒå¤šå¤«æ–¯å¡ï¼Œå‡ºç”Ÿäºæ³¢å…°åæ²™ï¼Œæ˜¯ä¸€ä½å¼€åˆ›æ€§çš„ç‰©ç†å­¦å®¶å’ŒåŒ–å­¦å®¶ã€‚
    å¥¹åœ¨æ”¾å°„æ€§ç ”ç©¶æ–¹é¢è¿›è¡Œäº†å¼€åˆ›æ€§çš„ç ”ç©¶ã€‚ä¸å¥¹çš„ä¸ˆå¤«çš®åŸƒå°”Â·å±…é‡Œä¸€èµ·ï¼Œ
    å¥¹å‘ç°äº†å…ƒç´ é’‹å’Œé•­ã€‚ç›ä¸½Â·å±…é‡Œæ˜¯ç¬¬ä¸€ä½è·å¾—è¯ºè´å°”å¥–çš„å¥³æ€§ï¼Œ
    ç¬¬ä¸€ä½ä¹Ÿæ˜¯å”¯ä¸€ä¸€ä½ä¸¤æ¬¡è·å¾—è¯ºè´å°”å¥–çš„å¥³æ€§ï¼Œ
    ä¹Ÿæ˜¯å”¯ä¸€ä¸€ä½åœ¨ä¸¤ä¸ªä¸åŒç§‘å­¦é¢†åŸŸè·å¾—è¯ºè´å°”å¥–çš„äººã€‚
    """
    
    print("ğŸ§ª æµ‹è¯•SPOä¸‰å…ƒç»„æå–å™¨")
    print("=" * 60)
    
    try:
        extractor = SPOTripleExtractor(verbose=True)
        result = extractor.extract_triples_from_text(
            test_text,
            chunk_size=50,
            overlap=10,
            verbose=True
        )
        
        print(f"\nğŸ“Š æå–ç»“æœ:")
        print(f"   æ€»å—æ•°: {result['total_chunks']}")
        print(f"   æˆåŠŸå—æ•°: {result['successful_chunks']}")
        print(f"   å¤±è´¥å—æ•°: {len(result['failed_chunks'])}")
        print(f"   æå–çš„ä¸‰å…ƒç»„æ•°: {len(result['triples'])}")
        
        # è§„èŒƒåŒ–
        normalized = extractor.normalize_triples(result['triples'])
        print(f"   è§„èŒƒåŒ–åçš„ä¸‰å…ƒç»„æ•°: {len(normalized)}")
        
        print(f"\nğŸ“‹ å‰5ä¸ªä¸‰å…ƒç»„:")
        for i, triple in enumerate(normalized[:5]):
            print(f"   {i+1}. {triple['subject']} --[{triple['predicate']}]--> {triple['object']}")
        
        return normalized
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return []


if __name__ == "__main__":
    test_spo_extractor()

