#!/usr/bin/env python3
"""
å…¬å…³ä¼ æ’­å†…å®¹å¤šæ ¼å¼é¢„å¤„ç†è„šæœ¬
æ”¯æŒPDFã€Excelã€CSVã€Wordã€PPTã€HTMLã€JSONã€TXTç­‰æ ¼å¼
"""

import os
import re
import json
import pandas as pd
from pathlib import Path
from docx import Document
from bs4 import BeautifulSoup
import PyPDF2
import pptx
import warnings
warnings.filterwarnings("ignore")

def read_pdf_file(file_path):
    """è¯»å–PDFæ–‡ä»¶"""
    try:
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text_content = []
            
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                text_content.append(page.extract_text())
            
            return '\n'.join(text_content)
    except Exception as e:
        print(f"Error reading PDF file {file_path}: {e}")
        return None

def read_excel_file(file_path):
    """è¯»å–Excelæ–‡ä»¶"""
    try:
        # è¯»å–æ‰€æœ‰å·¥ä½œè¡¨
        excel_file = pd.ExcelFile(file_path)
        text_content = []
        
        for sheet_name in excel_file.sheet_names:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            text_content.append(f"Sheet: {sheet_name}")
            text_content.append(df.to_string())
        
        return '\n'.join(text_content)
    except Exception as e:
        print(f"Error reading Excel file {file_path}: {e}")
        return None

def read_csv_file(file_path):
    """è¯»å–CSVæ–‡ä»¶"""
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
        return df.to_string()
    except Exception as e:
        try:
            # å°è¯•å…¶ä»–ç¼–ç 
            df = pd.read_csv(file_path, encoding='gbk')
            return df.to_string()
        except Exception as e2:
            print(f"Error reading CSV file {file_path}: {e2}")
            return None

def read_docx_file(file_path):
    """è¯»å–Wordæ–‡æ¡£"""
    try:
        doc = Document(file_path)
        text_content = []
        
        # æå–æ®µè½æ–‡æœ¬
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text_content.append(paragraph.text.strip())
        
        # æå–è¡¨æ ¼å†…å®¹
        for table in doc.tables:
            for row in table.rows:
                row_text = []
                for cell in row.cells:
                    if cell.text.strip():
                        row_text.append(cell.text.strip())
                if row_text:
                    text_content.append(" | ".join(row_text))
        
        return '\n'.join(text_content)
    except Exception as e:
        print(f"Error reading DOCX file {file_path}: {e}")
        return None

def read_pptx_file(file_path):
    """è¯»å–PowerPointæ–‡ä»¶"""
    try:
        prs = pptx.Presentation(file_path)
        text_content = []
        
        for slide_num, slide in enumerate(prs.slides, 1):
            text_content.append(f"Slide {slide_num}:")
            
            for shape in slide.shapes:
                if hasattr(shape, "text") and shape.text.strip():
                    text_content.append(shape.text.strip())
        
        return '\n'.join(text_content)
    except Exception as e:
        print(f"Error reading PPTX file {file_path}: {e}")
        return None

def read_html_file(file_path):
    """è¯»å–HTMLæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            html_content = file.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
        for script in soup(["script", "style"]):
            script.decompose()
        
        # æå–æ–‡æœ¬
        text_content = []
        for element in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'div']):
            if element.get_text().strip():
                text_content.append(element.get_text().strip())
        
        return '\n'.join(text_content)
    except Exception as e:
        print(f"Error reading HTML file {file_path}: {e}")
        return None

def read_json_file(file_path):
    """è¯»å–JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
        
        # å°†JSONè½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬
        if isinstance(data, dict):
            text_content = []
            for key, value in data.items():
                text_content.append(f"{key}: {value}")
            return '\n'.join(text_content)
        elif isinstance(data, list):
            return '\n'.join([str(item) for item in data])
        else:
            return str(data)
    except Exception as e:
        print(f"Error reading JSON file {file_path}: {e}")
        return None

def read_txt_file(file_path):
    """è¯»å–TXTæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read()
    except Exception as e:
        try:
            # å°è¯•å…¶ä»–ç¼–ç 
            with open(file_path, 'r', encoding='gbk') as file:
                return file.read()
        except Exception as e2:
            print(f"Error reading TXT file {file_path}: {e2}")
            return None

def extract_text_from_content(content, file_type):
    """ä»å†…å®¹ä¸­æå–å’Œæ ¼å¼åŒ–æ–‡æœ¬"""
    if not content:
        return None
    
    lines = content.split('\n')
    text_content = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # æ ¹æ®æ–‡ä»¶ç±»å‹å’Œå†…å®¹ç‰¹å¾åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é¢˜
        is_title = False
        
        if file_type in ['pdf', 'docx', 'pptx']:
            # å¯¹äºç»“æ„åŒ–æ–‡æ¡£ï¼Œåˆ¤æ–­æ ‡é¢˜
            if len(line) < 100 and (line.endswith('ï¼š') or line.endswith(':') or 
                                   'å“ç‰Œ' in line or 'æ¡ˆä¾‹' in line or 'ç­–ç•¥' in line or 
                                   'ä¼ æ’­' in line or 'è¥é”€' in line or 'åˆ†æ' in line):
                is_title = True
        elif file_type == 'html':
            # HTMLæ–‡æ¡£çš„æ ‡é¢˜åˆ¤æ–­
            if len(line) < 100 and ('å“ç‰Œ' in line or 'æ¡ˆä¾‹' in line or 'ç­–ç•¥' in line):
                is_title = True
        elif file_type in ['excel', 'csv']:
            # è¡¨æ ¼æ•°æ®çš„å¤„ç†
            if 'Sheet:' in line or line.startswith('Unnamed:'):
                is_title = True
        
        if is_title:
            text_content.append(f"Section: {line}")
        else:
            text_content.append(f"Content: {line}")
    
    return '\n'.join(text_content)

def save_text_to_file(text, output_path):
    """ä¿å­˜æå–çš„æ–‡æœ¬åˆ°æ–‡ä»¶"""
    try:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as file:
            file.write(text)
        print(f"Text saved to: {output_path}")
        return True
    except Exception as e:
        print(f"Error saving file {output_path}: {e}")
        return False

def process_multi_format_documents(input_dir="data/raw", output_dir="data/cleaned"):
    """å¤„ç†å¤šç§æ ¼å¼çš„å…¬å…³ä¼ æ’­æ–‡æ¡£"""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    if not input_path.exists():
        print(f"Input directory {input_dir} does not exist")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.mkdir(parents=True, exist_ok=True)
    
    # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
    supported_formats = {
        '.pdf': read_pdf_file,
        '.xlsx': read_excel_file,
        '.xls': read_excel_file,
        '.csv': read_csv_file,
        '.docx': read_docx_file,
        '.doc': read_docx_file,
        '.pptx': read_pptx_file,
        '.ppt': read_pptx_file,
        '.html': read_html_file,
        '.htm': read_html_file,
        '.json': read_json_file,
        '.txt': read_txt_file
    }
    
    # ç»Ÿè®¡å¤„ç†çš„æ–‡ä»¶
    processed_files = 0
    
    for file_path in input_path.iterdir():
        if file_path.is_file():
            file_ext = file_path.suffix.lower()
            
            if file_ext in supported_formats:
                print(f"\nProcessing: {file_path.name} ({file_ext})")
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = supported_formats[file_ext](file_path)
                
                if content:
                    # æå–æ–‡æœ¬
                    text_content = extract_text_from_content(content, file_ext[1:])
                    
                    if text_content:
                        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                        output_filename = file_path.stem + ".txt"
                        output_file_path = output_path / output_filename
                        
                        # ä¿å­˜æ–‡æœ¬
                        if save_text_to_file(text_content, output_file_path):
                            print(f"âœ… Successfully processed {file_path.name}")
                            processed_files += 1
                        else:
                            print(f"âŒ Failed to process {file_path.name}")
                    else:
                        print(f"âŒ No text content extracted from {file_path.name}")
                else:
                    print(f"âŒ Failed to read {file_path.name}")
            else:
                print(f"âš ï¸ Unsupported format: {file_path.name} ({file_ext})")
    
    print(f"\nğŸ“Š å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç†äº† {processed_files} ä¸ªæ–‡ä»¶")
    print(f"æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {', '.join(supported_formats.keys())}")

if __name__ == "__main__":
    print("ğŸš€ å…¬å…³ä¼ æ’­å¤šæ ¼å¼æ–‡æ¡£é¢„å¤„ç†å¼€å§‹")
    print("="*60)
    print("æ”¯æŒæ ¼å¼: PDF, Excel, CSV, Word, PowerPoint, HTML, JSON, TXT")
    print("="*60)
    
    # å¤„ç†æ–‡æ¡£
    process_multi_format_documents()
    
    print("\nâœ… å¤šæ ¼å¼é¢„å¤„ç†å®Œæˆï¼")
    print("å¤„ç†åçš„æ–‡ä»¶ä¿å­˜åœ¨ data/cleaned/ ç›®å½•ä¸­")


