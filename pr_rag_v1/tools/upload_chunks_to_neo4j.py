#!/usr/bin/env python3
"""
Chunksä¸Šä¼ åˆ°Neo4jæ•°æ®åº“å·¥å…·
å°†å·²æœ‰çš„chunksæ•°æ®ä¸Šä¼ åˆ°Neo4jçŸ¥è¯†å›¾è°±æ•°æ®åº“
"""

import os
import json
import sys
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from langchain_community.graphs import Neo4jGraph
import warnings
warnings.filterwarnings("ignore")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv('.env', override=True)

class ChunksUploader:
    """Chunksä¸Šä¼ åˆ°Neo4jæ•°æ®åº“ç±»"""
    
    def __init__(self):
        self.chunks_dir = Path("data/chunks")
        self.neo4j_config = {
            'uri': os.getenv('NEO4J_URI'),
            'username': os.getenv('NEO4J_USERNAME'),
            'password': os.getenv('NEO4J_PASSWORD'),
            'database': os.getenv('NEO4J_DATABASE') or 'neo4j'
        }
        
        # åˆå§‹åŒ–Neo4jè¿æ¥
        try:
            self.graph = Neo4jGraph(
                url=self.neo4j_config['uri'],
                username=self.neo4j_config['username'],
                password=self.neo4j_config['password'],
                database=self.neo4j_config['database']
            )
            print("âœ… Neo4jè¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Neo4jè¿æ¥å¤±è´¥: {e}")
            self.graph = None
    
    def check_chunks_files(self):
        """æ£€æŸ¥chunksæ–‡ä»¶"""
        if not self.chunks_dir.exists():
            print(f"âŒ Chunksç›®å½•ä¸å­˜åœ¨: {self.chunks_dir}")
            return []
        
        chunk_files = list(self.chunks_dir.glob("*_chunks.json"))
        if not chunk_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°chunksæ–‡ä»¶")
            return []
        
        print(f"âœ… æ‰¾åˆ° {len(chunk_files)} ä¸ªchunksæ–‡ä»¶")
        return chunk_files
    
    def load_chunks_data(self, chunk_file):
        """åŠ è½½chunksæ•°æ®"""
        try:
            with open(chunk_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return data
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {chunk_file}: {e}")
            return None
    
    def create_chunk_node(self, chunk_data, file_name):
        """åˆ›å»ºchunkèŠ‚ç‚¹"""
        try:
            # æå–chunkä¿¡æ¯
            chunk_id = chunk_data.get('id', f"{file_name}_{datetime.now().timestamp()}")
            text = chunk_data.get('text', '')
            metadata = chunk_data.get('metadata', {})
            
            # åˆ›å»ºèŠ‚ç‚¹å±æ€§
            node_properties = {
                'chunk_id': chunk_id,
                'text': text,
                'file_name': file_name,
                'content_type': metadata.get('content_type', 'unknown'),
                'industry': metadata.get('industry', 'unknown'),
                'brand_mentions': metadata.get('brand_mentions', []),
                'created_at': datetime.now().isoformat(),
                'source_file': file_name
            }
            
            # åˆ›å»ºCypheræŸ¥è¯¢
            cypher_query = """
            MERGE (c:PR_Chunk {chunk_id: $chunk_id})
            SET c.text = $text,
                c.file_name = $file_name,
                c.content_type = $content_type,
                c.industry = $industry,
                c.brand_mentions = $brand_mentions,
                c.created_at = $created_at,
                c.source_file = $source_file
            RETURN c
            """
            
            result = self.graph.query(cypher_query, node_properties)
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºèŠ‚ç‚¹å¤±è´¥: {e}")
            return False
    
    def create_relationships(self, chunk_data, file_name):
        """åˆ›å»ºå…³ç³»"""
        try:
            metadata = chunk_data.get('metadata', {})
            brand_mentions = metadata.get('brand_mentions', [])
            
            if not brand_mentions:
                return True
            
            chunk_id = chunk_data.get('id', f"{file_name}_{datetime.now().timestamp()}")
            
            # ä¸ºæ¯ä¸ªå“ç‰Œåˆ›å»ºå…³ç³»
            for brand in brand_mentions:
                # åˆ›å»ºå“ç‰ŒèŠ‚ç‚¹
                brand_query = """
                MERGE (b:Brand {name: $brand_name})
                SET b.industry = $industry,
                    b.last_mentioned = $created_at
                """
                
                self.graph.query(brand_query, {
                    'brand_name': brand,
                    'industry': metadata.get('industry', 'unknown'),
                    'created_at': datetime.now().isoformat()
                })
                
                # åˆ›å»ºchunkä¸å“ç‰Œçš„å…³ç³»
                relationship_query = """
                MATCH (c:PR_Chunk {chunk_id: $chunk_id})
                MATCH (b:Brand {name: $brand_name})
                MERGE (c)-[:MENTIONS_BRAND]->(b)
                """
                
                self.graph.query(relationship_query, {
                    'chunk_id': chunk_id,
                    'brand_name': brand
                })
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºå…³ç³»å¤±è´¥: {e}")
            return False
    
    def upload_file_chunks(self, chunk_file):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶çš„chunks"""
        file_name = chunk_file.stem.replace('_chunks', '')
        print(f"\nğŸ“¤ å¤„ç†æ–‡ä»¶: {file_name}")
        
        # åŠ è½½æ•°æ®
        chunks_data = self.load_chunks_data(chunk_file)
        if not chunks_data:
            return False
        
        # æ£€æŸ¥æ•°æ®æ ¼å¼
        if isinstance(chunks_data, list):
            chunks = chunks_data
        elif isinstance(chunks_data, dict) and 'chunks' in chunks_data:
            chunks = chunks_data['chunks']
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼: {file_name}")
            return False
        
        success_count = 0
        total_count = len(chunks)
        
        print(f"ğŸ“Š å¼€å§‹ä¸Šä¼  {total_count} ä¸ªchunks...")
        
        for i, chunk in enumerate(chunks, 1):
            try:
                # åˆ›å»ºchunkèŠ‚ç‚¹
                if self.create_chunk_node(chunk, file_name):
                    # åˆ›å»ºå…³ç³»
                    self.create_relationships(chunk, file_name)
                    success_count += 1
                
                if i % 10 == 0:
                    print(f"  è¿›åº¦: {i}/{total_count} ({i/total_count*100:.1f}%)")
                    
            except Exception as e:
                print(f"âŒ å¤„ç†chunk {i} å¤±è´¥: {e}")
        
        print(f"âœ… {file_name}: {success_count}/{total_count} chunksä¸Šä¼ æˆåŠŸ")
        return success_count > 0
    
    def create_indexes(self):
        """åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½"""
        try:
            indexes = [
                "CREATE INDEX IF NOT EXISTS FOR (c:PR_Chunk) ON (c.chunk_id)",
                "CREATE INDEX IF NOT EXISTS FOR (c:PR_Chunk) ON (c.file_name)",
                "CREATE INDEX IF NOT EXISTS FOR (c:PR_Chunk) ON (c.content_type)",
                "CREATE INDEX IF NOT EXISTS FOR (b:Brand) ON (b.name)",
                "CREATE INDEX IF NOT EXISTS FOR (b:Brand) ON (b.industry)"
            ]
            
            for index_query in indexes:
                self.graph.query(index_query)
            
            print("âœ… ç´¢å¼•åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
            return False
    
    def get_upload_stats(self):
        """è·å–ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # ç»Ÿè®¡chunkæ•°é‡
            chunk_count_query = "MATCH (c:PR_Chunk) RETURN count(c) as chunk_count"
            result = self.graph.query(chunk_count_query)
            chunk_count = result[0]['chunk_count'] if result else 0
            
            # ç»Ÿè®¡å“ç‰Œæ•°é‡
            brand_count_query = "MATCH (b:Brand) RETURN count(b) as brand_count"
            result = self.graph.query(brand_count_query)
            brand_count = result[0]['brand_count'] if result else 0
            
            # ç»Ÿè®¡å…³ç³»æ•°é‡
            relationship_count_query = "MATCH ()-[r]->() RETURN count(r) as relationship_count"
            result = self.graph.query(relationship_count_query)
            relationship_count = result[0]['relationship_count'] if result else 0
            
            return {
                'chunk_count': chunk_count,
                'brand_count': brand_count,
                'relationship_count': relationship_count
            }
            
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def run(self):
        """è¿è¡Œä¸Šä¼ æµç¨‹"""
        print("ğŸš€ å¯åŠ¨Chunksä¸Šä¼ åˆ°Neo4jæµç¨‹...")
        print("=" * 60)
        
        # æ£€æŸ¥Neo4jè¿æ¥
        if not self.graph:
            print("âŒ Neo4jè¿æ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return False
        
        # æ£€æŸ¥chunksæ–‡ä»¶
        chunk_files = self.check_chunks_files()
        if not chunk_files:
            return False
        
        # åˆ›å»ºç´¢å¼•
        print("\nğŸ”§ åˆ›å»ºæ•°æ®åº“ç´¢å¼•...")
        self.create_indexes()
        
        # ä¸Šä¼ æ¯ä¸ªæ–‡ä»¶
        success_files = 0
        total_files = len(chunk_files)
        
        for chunk_file in chunk_files:
            if self.upload_file_chunks(chunk_file):
                success_files += 1
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š ä¸Šä¼ å®Œæˆç»Ÿè®¡:")
        print("=" * 60)
        
        stats = self.get_upload_stats()
        if stats:
            print(f"âœ… æˆåŠŸä¸Šä¼ æ–‡ä»¶: {success_files}/{total_files}")
            print(f"ğŸ“„ Neo4jä¸­çš„ChunkèŠ‚ç‚¹: {stats['chunk_count']}")
            print(f"ğŸ·ï¸ Neo4jä¸­çš„BrandèŠ‚ç‚¹: {stats['brand_count']}")
            print(f"ğŸ”— Neo4jä¸­çš„å…³ç³»æ•°é‡: {stats['relationship_count']}")
        else:
            print(f"âœ… æˆåŠŸä¸Šä¼ æ–‡ä»¶: {success_files}/{total_files}")
        
        print("\nğŸ‰ Chunksä¸Šä¼ æµç¨‹å®Œæˆï¼")
        print("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨é€‰é¡¹5è¿›è¡Œå¢å¼ºRAGæŸ¥è¯¢")
        
        return success_files > 0

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“¤ Chunksä¸Šä¼ åˆ°Neo4jå·¥å…·")
    print("=" * 60)
    
    uploader = ChunksUploader()
    success = uploader.run()
    
    if success:
        print("\nâœ… ä¸Šä¼ æˆåŠŸï¼")
    else:
        print("\nâŒ ä¸Šä¼ å¤±è´¥ï¼")
        sys.exit(1)

if __name__ == "__main__":
    main()


